{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import os,sys\n",
    "import cv2\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras \n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tqdm import tqdm\n",
    "from scipy import ndimage\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "from sklearn.model_selection import train_test_split\n",
    "from IPython.display import Image as _Imgdis\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Directory variables\n",
    "DATADIR = r\".\" # The directory to SAFE and UNSAFE PFM/PNG images\n",
    "STATES_PNG = [\"Safe_Collection\", \"Unsafe_Collection\"] #Sub-directories for png files\n",
    "SAFE_IMG_PNG = STATES_PNG[0] \n",
    "UNSAFE_IMG_PNG = STATES_PNG[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildDF():\n",
    "    #dataToAR()\n",
    "\n",
    "    #appends safe & unsafe images to the appropriate lists to later use as labels\n",
    "    imageSafeList = pd.Series()\n",
    "    imageUnsafeList = pd.Series()\n",
    "    images_df = pd.DataFrame(columns=[\"image_Data\", \"State\"])\n",
    "    \n",
    "    \n",
    "    for file in os.listdir(DATADIR + '\\\\' + SAFE_IMG_PNG):\n",
    "        try:\n",
    "            \n",
    "            frame = cv2.imread(DATADIR + '\\\\' + SAFE_IMG_PNG + '\\\\' + file)\n",
    "            frame = cv2.resize(frame, (50, 50))\n",
    "            images_df.loc[file] = [frame, \"Safe\"]\n",
    "    \n",
    "        except Exception as e:\n",
    "            continue\n",
    "\n",
    "    for file in os.listdir(DATADIR + '\\\\' + UNSAFE_IMG_PNG):\n",
    "        try:\n",
    "            frame = cv2.imread(DATADIR + '\\\\' + UNSAFE_IMG_PNG + '\\\\' + file)\n",
    "            frame = cv2.resize(frame, (50, 50))\n",
    "            images_df.loc[file] = [frame, \"Unsafe\"]\n",
    "\n",
    "        except Exception as e:\n",
    "            continue\n",
    "\n",
    "    return images_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def dataPrep(image_df): \\n    folder_safe = DATADIR + \\'\\\\\\'+ STATES_PNG[0]\\n    folder_unsafe = DATADIR + \\'\\\\\\'+ STATES_PNG[1]\\n    \\n    safeFiles = [x for x in os.listdir(folder_safe) if os.path.isfile(os.path.join(folder_safe, x))]\\n    unsafeFiles = [y for y in os.listdir(folder_unsafe) if os.path.isfile(os.path.join(folder_unsafe, y))]\\n\\n    print(\"Working with {0} images\".format(len(safeFiles)))\\n    print(\"Image examples: \")\\n    \\n    print(type(safeFiles))\\n    \\n    for i in range(40, 42):\\n        print(safeFiles[i])\\n        display(_Imgdis(filename=folder_safe + \"/\" + safeFiles[i], width=240, height=320))\\n    \\n    train_data = []\\n    y_train = []\\n    for file in safeFiles:\\n        frame = cv2.imread(DATADIR + \\'\\\\\\' + STATES_PNG[0] + \\'\\\\\\' + file)\\n        im = Image.open(frame)\\n        print(im.size)\\n        train_data.append(file)\\n        y_train.append(\"safe\")\\n        \\n        \\n    print(\"Files in train_data: %d\" % len(train_data))\\n    \\n    channels = 3\\n    nb_classes = 1\\n    \\n    dataset = np.ndarray(shape=(len(train_data), channels, 50, 50), dtype=np.float32)\\n    \\n    i = 0\\n    for file in train_data:\\n        img = load_img(folder_safe+\"/\"+file)\\n        img.thumbnail((50, 50))\\n        #numpy array conversion\\n        x = img_to_array(img)\\n        x.reshape((3,120,160))\\n        #normalize\\n        x = (x - 128.0) / 128.0\\n        dataset[i] = x\\n        i += 1\\n        if i % 250 == 0:\\n            print(\"%d images to array\" % i)\\n    print(\"All images to array!\")\\n    splitData(y_train, x_data)\\n    '"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''def dataPrep(image_df): \n",
    "    folder_safe = DATADIR + '\\\\'+ STATES_PNG[0]\n",
    "    folder_unsafe = DATADIR + '\\\\'+ STATES_PNG[1]\n",
    "    \n",
    "    safeFiles = [x for x in os.listdir(folder_safe) if os.path.isfile(os.path.join(folder_safe, x))]\n",
    "    unsafeFiles = [y for y in os.listdir(folder_unsafe) if os.path.isfile(os.path.join(folder_unsafe, y))]\n",
    "\n",
    "    print(\"Working with {0} images\".format(len(safeFiles)))\n",
    "    print(\"Image examples: \")\n",
    "    \n",
    "    print(type(safeFiles))\n",
    "    \n",
    "    for i in range(40, 42):\n",
    "        print(safeFiles[i])\n",
    "        display(_Imgdis(filename=folder_safe + \"/\" + safeFiles[i], width=240, height=320))\n",
    "    \n",
    "    train_data = []\n",
    "    y_train = []\n",
    "    for file in safeFiles:\n",
    "        frame = cv2.imread(DATADIR + '\\\\' + STATES_PNG[0] + '\\\\' + file)\n",
    "        im = Image.open(frame)\n",
    "        print(im.size)\n",
    "        train_data.append(file)\n",
    "        y_train.append(\"safe\")\n",
    "        \n",
    "        \n",
    "    print(\"Files in train_data: %d\" % len(train_data))\n",
    "    \n",
    "    channels = 3\n",
    "    nb_classes = 1\n",
    "    \n",
    "    dataset = np.ndarray(shape=(len(train_data), channels, 50, 50), dtype=np.float32)\n",
    "    \n",
    "    i = 0\n",
    "    for file in train_data:\n",
    "        img = load_img(folder_safe+\"/\"+file)\n",
    "        img.thumbnail((50, 50))\n",
    "        #numpy array conversion\n",
    "        x = img_to_array(img)\n",
    "        x.reshape((3,120,160))\n",
    "        #normalize\n",
    "        x = (x - 128.0) / 128.0\n",
    "        dataset[i] = x\n",
    "        i += 1\n",
    "        if i % 250 == 0:\n",
    "            print(\"%d images to array\" % i)\n",
    "    print(\"All images to array!\")\n",
    "    splitData(y_train, x_data)\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataSplit(dataframe):\n",
    "    Y = dataframe['State'].values.reshape(dataframe.shape[0],1)\n",
    "    dataframe = dataframe.drop('State', 1)\n",
    "    dataset = dataframe.values\n",
    "    #print(dataset)\n",
    "    X = dataset[:,0:dataset.shape[1]]\n",
    "    \n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=0.2)\n",
    "    \n",
    "    print(type(X_train))\n",
    "    print(type(Y_train))\n",
    "    CNN_training(X_train, X_test,Y_train,Y_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN_training(x_train, x_test, y_train,y_test):\n",
    "    \n",
    "    pickle_out = open(\"X.pickle\", \"wb\")\n",
    "    pickle.dump(x_train,pickle_out)\n",
    "    pickle_out.close()\n",
    "\n",
    "    pickle_out = open(\"y.pickle\", \"wb\")\n",
    "    pickle.dump(y_train,pickle_out)\n",
    "    pickle_out.close()\n",
    "\n",
    "    pickle_in = open(\"X.pickle\", \"rb\")\n",
    "    X_train = pickle.load(pickle_in)\n",
    "\n",
    "    pickle_in = open(\"y.pickle\", \"rb\")\n",
    "    y_train = pickle.load(pickle_in)\n",
    "\n",
    "    x_train = x_train/255.0 #normalize\n",
    "    x_train = np.array(x_train)\n",
    "    \n",
    "    dense_layers = [0]\n",
    "    layer_sizes = [64]\n",
    "    conv_layers = [1]\n",
    "\n",
    "    for dense_layer in dense_layers:\n",
    "        for layer_size in layer_sizes:\n",
    "            for conv_layer in conv_layers:\n",
    "                NAME = \"{}-conv-{}-nodes-{}-dense-{}\".format(conv_layer, layer_size, dense_layer, int(time.time()))\n",
    "                print(NAME)\n",
    "                model = Sequential() #feed-forward network\n",
    "                model.add(Conv2D(layer_size, (3, 3), input_shape=x_train.shape[:]))\n",
    "                model.add(Activation('relu'))\n",
    "                model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "            for l in range(conv_layer-1):\n",
    "                model.add(Conv2D(layer_size, (3, 3)))\n",
    "                model.add(Activation('relu'))\n",
    "                model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "            model.add(Flatten())\n",
    "\n",
    "            for _ in range(dense_layer):\n",
    "                model.add(Dense(layer_size))\n",
    "                model.add(Activation('relu'))\n",
    "\n",
    "            model.add(Dense(1))\n",
    "            model.add(Activation('sigmoid'))\n",
    "\n",
    "            tensorboard = TensorBoard(log_dir=\"logs/{}\".format(NAME))\n",
    "\n",
    "            model.compile(loss='binary_crossentropy',\n",
    "                            optimizer='adam',\n",
    "                            metrics=['accuracy'],\n",
    "                            )\n",
    "\n",
    "            model.fit(x_train, y_train,\n",
    "                        batch_size=32,\n",
    "                        epochs=10,\n",
    "                        validation_split=0.1,\n",
    "                        callbacks=[tensorboard])\n",
    "\n",
    "    model.save('CNN_tester.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "1-conv-64-nodes-0-dense-1574309084\n",
      "WARNING:tensorflow:From C:\\Users\\JohnQ\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer conv2d is incompatible with the layer: expected ndim=4, found ndim=3. Full shape received: [None, 80, 1]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-69-ea302f38160a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mimages_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuildDF\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mdataSplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-69-ea302f38160a>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;31m#Here we are building a dataframe of our images and their labels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mimages_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuildDF\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mdataSplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-67-4e17819b4ce1>\u001b[0m in \u001b[0;36mdataSplit\u001b[1;34m(dataframe)\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mCNN_training\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-68-a5586a09df8f>\u001b[0m in \u001b[0;36mCNN_training\u001b[1;34m(x_train, x_test, y_train, y_test)\u001b[0m\n\u001b[0;32m     28\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNAME\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m                 \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#feed-forward network\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m                 \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mActivation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    455\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36madd\u001b[1;34m(self, layer)\u001b[0m\n\u001b[0;32m    172\u001b[0m           \u001b[1;31m# and create the node connecting the current layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m           \u001b[1;31m# to the input layer we just created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 174\u001b[1;33m           \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    175\u001b[0m           \u001b[0mset_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    584\u001b[0m         \u001b[1;31m# the corresponding TF subgraph inside `backend.get_graph()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m         input_spec.assert_input_compatibility(self.input_spec, inputs,\n\u001b[1;32m--> 586\u001b[1;33m                                               self.name)\n\u001b[0m\u001b[0;32m    587\u001b[0m         \u001b[0mgraph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    121\u001b[0m                          \u001b[1;34m'expected ndim='\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m', found ndim='\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m                          \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'. Full shape received: '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m                          str(x.shape.as_list()))\n\u001b[0m\u001b[0;32m    124\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_ndim\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m       \u001b[0mndim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndims\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input 0 of layer conv2d is incompatible with the layer: expected ndim=4, found ndim=3. Full shape received: [None, 80, 1]"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    #Here we are building a dataframe of our images and their labels\n",
    "    images_df = buildDF()\n",
    "    dataSplit(images_df)\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
